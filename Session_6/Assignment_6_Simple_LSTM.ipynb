{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 6- Simple LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76cff18f918a4f82b1421be22a23ddd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_42380510ac9144eabb1647d47a4e8e9c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b75836441be41159c0b3aa967df98f0",
              "IPY_MODEL_2b607e5a16eb4795904356cf30e33b72"
            ]
          }
        },
        "42380510ac9144eabb1647d47a4e8e9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5b75836441be41159c0b3aa967df98f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_d91622c7ce114f7780a41ca8e8dbbb51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0.04MB of 0.04MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e38c7d18088349d3a45f6e09cad917e2"
          }
        },
        "2b607e5a16eb4795904356cf30e33b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f428b7d62f7d4fc9ae355ef21ef02b27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_46994ef2558249b8bb3edbcd9ce17d49"
          }
        },
        "d91622c7ce114f7780a41ca8e8dbbb51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e38c7d18088349d3a45f6e09cad917e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f428b7d62f7d4fc9ae355ef21ef02b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "46994ef2558249b8bb3edbcd9ce17d49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ooq_tTPbBE0N"
      },
      "source": [
        "%%capture\n",
        "!pip install wandb --upgrade"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "vq5e2upOBHby",
        "outputId": "6a69ef6c-7773-4902-96e3-ae7698ca4e31"
      },
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY4eAjHGbFON",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d813ecf8-58bf-4d50-94bc-ec1cf78fa925"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/tweets.csv\")\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  labels\n",
              "0  Obama has called the GOP budget social Darwini...       1\n",
              "1  In his teen years, Obama has been known to use...       0\n",
              "2  IPA Congratulates President Barack Obama for L...       0\n",
              "3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n",
              "4  RT @wardollarshome: Obama has approved more ta...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rE-ylf6C6BJD",
        "outputId": "0067ab0a-8ffe-4403-aa38-6506cc531c22"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1364, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkxhrQox6Ju3",
        "outputId": "a54ba67f-1a4e-4641-8125-99e6142384ff"
      },
      "source": [
        "df.labels.value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDIyapAa6Pjr"
      },
      "source": [
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kqZx2hG6e4Q",
        "outputId": "713674a3-bd7f-4e55-ca9d-c7cf44e77e60"
      },
      "source": [
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fed76fe75d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "db3eiDVx6mKf"
      },
      "source": [
        "Tweet = torchtext.legacy.data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = torchtext.legacy.data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-by1zHIV7LPI"
      },
      "source": [
        "fields = [('tweet', Tweet), ('label', Label)]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxmCFTgk797i"
      },
      "source": [
        "example = [torchtext.legacy.data.Example.fromlist([df.tweets[i],df.labels[i]], fields) for i in range(df.shape[0])] "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Lj9XCy38OqE"
      },
      "source": [
        "twitterDataset = torchtext.legacy.data.Dataset(example, fields)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PIA3n0l8m2x"
      },
      "source": [
        "(train, valid) = twitterDataset.split(split_ratio=[85, 15], random_state = random.seed(SEED))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91fhtSKS8y3T",
        "outputId": "29ecfc75-0aa1-487e-89df-45c760097bd8"
      },
      "source": [
        "len(train), len(valid)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1159, 205)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCDhbBKJ81ZK",
        "outputId": "a60400fa-589f-49ea-ca3a-bc77adedb57a"
      },
      "source": [
        "vars(train.examples[11])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 1,\n",
              " 'tweet': ['@sweetbay',\n",
              "  'That',\n",
              "  'was',\n",
              "  'Paul',\n",
              "  'Ryan',\n",
              "  \"'s\",\n",
              "  'budget',\n",
              "  '.',\n",
              "  'How',\n",
              "  'did',\n",
              "  'Obama',\n",
              "  \"'s\",\n",
              "  'budget',\n",
              "  'do',\n",
              "  '?',\n",
              "  'Getting',\n",
              "  'educated',\n",
              "  'on',\n",
              "  'the',\n",
              "  'facts',\n",
              "  'is',\n",
              "  'the',\n",
              "  'first',\n",
              "  'step',\n",
              "  'in',\n",
              "  'losing',\n",
              "  'that',\n",
              "  'liberalism',\n",
              "  '!']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_K23gxx84-K"
      },
      "source": [
        "Tweet.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCPG8VrE9MKq",
        "outputId": "3c4efb3b-24d4-4297-c2fd-fb67344766cb"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4651\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1069), (':', 783), ('#', 780), ('.', 761), (',', 598), ('\"', 550), ('the', 542), ('RT', 516), ('?', 419), ('to', 400)]\n",
            "Labels :  defaultdict(None, {0: 0, 1: 1, 2: 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBmMQQcX9SZk",
        "outputId": "cb3766d2-1606-4f20-e9d3-67f7566c5622"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIJyulXA9sEr"
      },
      "source": [
        "train_iterator, valid_iterator = torchtext.legacy.data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweet),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kgqqK75FLEV",
        "outputId": "727286c5-7ee7-4240-c594-0d40883d67cc"
      },
      "source": [
        "next(iter(train_iterator))\n",
        "#len(train.examples[11].tweet)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.legacy.data.batch.Batch of size 32]\n",
              "\t[.tweet]:('[torch.cuda.LongTensor of size 32x8 (GPU 0)]', '[torch.cuda.LongTensor of size 32 (GPU 0)]')\n",
              "\t[.label]:[torch.cuda.LongTensor of size 32 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_NVSpoV-Uaj"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNQnNcH6-oZZ"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier_connected_arch(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=1, \n",
        "                           batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        self.decoder = nn.LSTM(100, \n",
        "                           hidden_dim, \n",
        "                           num_layers=1, \n",
        "                           batch_first=True)\n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "\n",
        "        packed_encoded_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "\n",
        "        packed_decoded_output, (hidden, cell) = self.decoder(packed_encoded_output)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output, packed_encoded_output, packed_decoded_output"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awrJKTIY_JyI"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier_disconnected_arch(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=1, \n",
        "                           batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        self.decoder = nn.LSTM(100, \n",
        "                           hidden_dim, \n",
        "                           num_layers=1, \n",
        "                           batch_first=True)\n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        \n",
        "        encoded_output, (hidden, cell) = self.encoder(embedded)\n",
        "        last_layer_output = encoded_output.data[:,-1:,:]\n",
        "\n",
        "        output_stack = []\n",
        "        for i in range(4):\n",
        "                decoded_output, (hidden, cell) = self.decoder(last_layer_output)\n",
        "                output_stack.append(decoded_output)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "\n",
        "        return output, encoded_output, output_stack"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFNWimMMAKya"
      },
      "source": [
        "config = dict(\n",
        "    size_of_vocab = len(Tweet.vocab),\n",
        "    embedding_dim = 300,\n",
        "    num_hidden_nodes = 100,\n",
        "    num_output_nodes = 3,\n",
        "    num_layers = 1,\n",
        "    dropout = 0.2\n",
        "    )\n",
        "\n",
        "# Define hyperparameters\n",
        "\n",
        "config[\"size_of_vocab\"]\n",
        "# Instantiate the model classifier_connected_arch\n",
        "# model = classifier_connected_arch(config[\"size_of_vocab\"], config[\"embedding_dim\"], config[\"num_hidden_nodes\"], config[\"num_output_nodes\"], config[\"num_layers\"], dropout = config[\"dropout\"])\n",
        "model = classifier_disconnected_arch(config[\"size_of_vocab\"], config[\"embedding_dim\"], config[\"num_hidden_nodes\"], config[\"num_output_nodes\"], config[\"num_layers\"], dropout = config[\"dropout\"])\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRextCcAASGO",
        "outputId": "61d1733c-5f45-4f1e-ec81-1dd31feb6056"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier_disconnected_arch(\n",
            "  (embedding): Embedding(4651, 300)\n",
            "  (encoder): LSTM(300, 100, batch_first=True)\n",
            "  (decoder): LSTM(100, 100, batch_first=True)\n",
            "  (fc): Linear(in_features=100, out_features=3, bias=True)\n",
            ")\n",
            "The model has 1,637,203 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPK6b19HATLm"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)\n"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8t9iWwqAify"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        tweet, tweet_lengths = batch.tweet  \n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions, _, _ = model(tweet, tweet_lengths)  \n",
        "        predictions = predictions.squeeze()\n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMBXHd5JAuX-"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            tweet, tweet_lengths = batch.tweet\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions, _ , _ = model(tweet, tweet_lengths)\n",
        "            predictions = predictions.squeeze()\n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "76cff18f918a4f82b1421be22a23ddd0",
            "42380510ac9144eabb1647d47a4e8e9c",
            "5b75836441be41159c0b3aa967df98f0",
            "2b607e5a16eb4795904356cf30e33b72",
            "d91622c7ce114f7780a41ca8e8dbbb51",
            "e38c7d18088349d3a45f6e09cad917e2",
            "f428b7d62f7d4fc9ae355ef21ef02b27",
            "46994ef2558249b8bb3edbcd9ce17d49"
          ]
        },
        "id": "q7UPwN0KAvVq",
        "outputId": "d17605c0-0fac-41e4-c42b-3987ff68aa0f"
      },
      "source": [
        "N_EPOCHS = 20\n",
        "best_valid_loss = float('inf')\n",
        "with wandb.init(project=\"session-6\", config=config):\n",
        "    wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "    for epoch in range(N_EPOCHS):\n",
        "        \n",
        "        # train the model\n",
        "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "        \n",
        "        # evaluate the model\n",
        "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "        \n",
        "        # save the best model\n",
        "        if valid_loss < best_valid_loss:\n",
        "            best_valid_loss = valid_loss\n",
        "            torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "        wandb.log({\"epoch\": epoch, \"train_loss\": train_loss , \"train_acc\": train_acc,  \"val_loss\": valid_loss, \"val_acc\": valid_acc})\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.31<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">soft-durian-8</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/pralay/session-6\" target=\"_blank\">https://wandb.ai/pralay/session-6</a><br/>\n",
              "                Run page: <a href=\"https://wandb.ai/pralay/session-6/runs/rwp4vys0\" target=\"_blank\">https://wandb.ai/pralay/session-6/runs/rwp4vys0</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210610_153125-rwp4vys0</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 1.086 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1.076 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1.071 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1.056 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1.052 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1.032 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1.029 | Train Acc: 69.12%\n",
            "\t Val. Loss: 1.000 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 1.002 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.973 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.972 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.950 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.944 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.932 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.930 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.919 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.920 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.910 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.906 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.903 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.901 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.897 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.890 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.892 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.890 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.889 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.878 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.886 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.876 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.885 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.875 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.883 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.870 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.881 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.870 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.880 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.868 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.880 |  Val. Acc: 68.30% \n",
            "\n",
            "\tTrain Loss: 0.865 | Train Acc: 69.12%\n",
            "\t Val. Loss: 0.879 |  Val. Acc: 68.30% \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 257<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76cff18f918a4f82b1421be22a23ddd0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210610_153125-rwp4vys0/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210610_153125-rwp4vys0/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>19</td></tr><tr><td>train_loss</td><td>0.86537</td></tr><tr><td>train_acc</td><td>0.69124</td></tr><tr><td>val_loss</td><td>0.87902</td></tr><tr><td>val_acc</td><td>0.68304</td></tr><tr><td>_runtime</td><td>12</td></tr><tr><td>_timestamp</td><td>1623339097</td></tr><tr><td>_step</td><td>19</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>train_loss</td><td>██▇▆▅▄▃▃▃▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_runtime</td><td>▁▂▂▃▃▃▃▄▄▅▅▅▆▆▆▆▇▇██</td></tr><tr><td>_timestamp</td><td>▁▂▂▃▃▃▃▄▄▅▅▅▆▆▆▆▇▇██</td></tr><tr><td>_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">soft-durian-8</strong>: <a href=\"https://wandb.ai/pralay/session-6/runs/rwp4vys0\" target=\"_blank\">https://wandb.ai/pralay/session-6/runs/rwp4vys0</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXCGxks4AxT3"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1:\"Positive\", 2:\"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    print(tokenized)\n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction, enc, dec = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()], enc, dec, tokenized"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1mmb9YiHWOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70ba4e39-bba6-4eaf-d89a-0566c388ac5c"
      },
      "source": [
        "pred, enc, dec, tokenized = classify_tweet(\"A valid explanation for why Trump won't let women on the golf course.\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['A', 'valid', 'explanation', 'for', 'why', 'Trump', 'wo', \"n't\", 'let', 'women', 'on', 'the', 'golf', 'course', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_Kk6-VciqT7",
        "outputId": "82aa39d6-408c-463c-b858-3636b49d4ce6"
      },
      "source": [
        "enc.data.shape[0]"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XU_DlC1HY5T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2902eb20-f680-4ef8-b899-6e5cf77bd651"
      },
      "source": [
        "for i in range(enc.data.shape[1]):\n",
        "    print(tokenized[i])\n",
        "    print(enc[0][i])\n",
        "    print(\"-\"* 100)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A\n",
            "tensor([ 0.0431,  0.3128, -0.0834, -0.0561,  0.0753, -0.4185, -0.0869,  0.0546,\n",
            "        -0.0699, -0.0739, -0.2454,  0.1826,  0.0034,  0.1956, -0.2409, -0.0176,\n",
            "        -0.1535,  0.0246,  0.2640, -0.1745, -0.0527,  0.1092,  0.3016,  0.2156,\n",
            "        -0.0108,  0.0161,  0.1804,  0.0386, -0.2951, -0.3025,  0.0943, -0.1377,\n",
            "        -0.2137,  0.0958, -0.0568,  0.1755, -0.0952,  0.0382, -0.0458, -0.0078,\n",
            "        -0.0657,  0.0849,  0.0266, -0.0072,  0.0755, -0.2042,  0.3718,  0.0024,\n",
            "        -0.2598,  0.3956, -0.1675,  0.1869, -0.0673, -0.0793,  0.0922,  0.0134,\n",
            "        -0.2729,  0.0040,  0.0280, -0.0348,  0.3063,  0.1800, -0.1911, -0.0460,\n",
            "        -0.0604,  0.1184, -0.3419, -0.1800,  0.0823, -0.0234,  0.2799,  0.1220,\n",
            "         0.0264, -0.1698,  0.0613,  0.0186,  0.0480,  0.2481,  0.1661, -0.0455,\n",
            "        -0.0689,  0.0621,  0.0337, -0.1824,  0.2746, -0.1772,  0.0857,  0.0864,\n",
            "         0.0382,  0.0246, -0.0810, -0.0392,  0.1773, -0.0134, -0.2248,  0.0152,\n",
            "         0.0447,  0.2105, -0.3283,  0.0582], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "valid\n",
            "tensor([ 0.0307,  0.1018, -0.3768, -0.2489,  0.0265, -0.2424,  0.0519,  0.0421,\n",
            "        -0.2462, -0.5975,  0.0748,  0.1644,  0.0163, -0.0997,  0.1633, -0.0525,\n",
            "        -0.0594, -0.0826,  0.0925, -0.0995,  0.0513,  0.0386,  0.2850,  0.0949,\n",
            "        -0.1925,  0.1351,  0.1478, -0.0140,  0.0772, -0.4298,  0.0426, -0.0972,\n",
            "         0.0716,  0.3239,  0.0627,  0.0384, -0.1808,  0.0796,  0.0861, -0.1394,\n",
            "        -0.1807,  0.1236,  0.0163, -0.0633, -0.0541, -0.3236,  0.1944,  0.2158,\n",
            "        -0.3878,  0.4783,  0.1019, -0.0472, -0.1441, -0.1916,  0.2661,  0.0168,\n",
            "        -0.3012, -0.0541, -0.2304, -0.0008, -0.0948, -0.0076,  0.0371,  0.0644,\n",
            "         0.0160,  0.2371, -0.2665, -0.1123,  0.1386, -0.1799,  0.5976,  0.1871,\n",
            "        -0.2139, -0.0990,  0.3195, -0.0086, -0.0776,  0.1977, -0.4754, -0.2541,\n",
            "        -0.0182, -0.0235,  0.0903,  0.0535,  0.2072, -0.1058,  0.2466,  0.2406,\n",
            "         0.0624, -0.4237, -0.0257,  0.2524, -0.0594,  0.0990, -0.0983,  0.1055,\n",
            "         0.0893, -0.1063, -0.0889,  0.1914], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "explanation\n",
            "tensor([-0.0748, -0.1740,  0.1574,  0.2156, -0.3002, -0.1126, -0.0461,  0.1475,\n",
            "         0.1758, -0.3838,  0.2383,  0.1884,  0.1908, -0.0037, -0.2942, -0.0538,\n",
            "        -0.0690,  0.0230, -0.0338, -0.1131, -0.0881,  0.0845,  0.1865, -0.0928,\n",
            "        -0.0090,  0.0420, -0.0077,  0.0053,  0.1162,  0.0315,  0.0715, -0.0489,\n",
            "         0.2034, -0.0532,  0.0865,  0.2411, -0.2900,  0.1971,  0.0465, -0.0098,\n",
            "        -0.0184,  0.1092, -0.1316,  0.1032, -0.0841,  0.1228,  0.0203,  0.3956,\n",
            "        -0.0508,  0.5409, -0.2310,  0.1812, -0.2177, -0.2777,  0.2292, -0.0777,\n",
            "        -0.1575, -0.1127, -0.0756,  0.2357,  0.1720,  0.0455,  0.2412, -0.0623,\n",
            "        -0.1399,  0.1945, -0.5084, -0.1461,  0.0610, -0.1026,  0.3733,  0.0794,\n",
            "         0.0029, -0.1687, -0.0235, -0.0720, -0.0380, -0.1009, -0.4165, -0.1707,\n",
            "        -0.1651,  0.0993, -0.1095,  0.1146,  0.2315,  0.0414, -0.1403,  0.0634,\n",
            "         0.2355, -0.0794,  0.1248,  0.0213,  0.0109, -0.0432,  0.3454,  0.1015,\n",
            "        -0.3657, -0.1205, -0.0299,  0.1656], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "for\n",
            "tensor([-0.0827, -0.4383, -0.0046, -0.2169, -0.2452, -0.0221,  0.0646,  0.3014,\n",
            "        -0.0264, -0.3565,  0.4036,  0.2500,  0.0986, -0.1744, -0.1907, -0.1323,\n",
            "         0.0430, -0.4877,  0.0880,  0.1394,  0.2408,  0.1091,  0.1776, -0.0832,\n",
            "         0.0845, -0.1324,  0.0073, -0.0261, -0.0997, -0.0236,  0.0027,  0.5405,\n",
            "         0.0608,  0.0632,  0.3603, -0.0146, -0.2480, -0.0432,  0.3044, -0.1807,\n",
            "         0.0600,  0.0451, -0.0667,  0.1209, -0.0424, -0.1270, -0.3252,  0.1300,\n",
            "        -0.3698,  0.1208, -0.2121,  0.2134, -0.4016,  0.0028, -0.0047, -0.0232,\n",
            "        -0.2385, -0.3529,  0.1888,  0.0785,  0.2644,  0.2737,  0.2653, -0.0961,\n",
            "        -0.0894, -0.2770, -0.4502, -0.1076, -0.0019, -0.3385,  0.1735, -0.0367,\n",
            "         0.1178, -0.1017,  0.3853, -0.2066,  0.0215, -0.0330, -0.1197, -0.1287,\n",
            "         0.3677, -0.1323,  0.1379,  0.4204,  0.1166, -0.0242, -0.0836, -0.0176,\n",
            "        -0.0779, -0.2328,  0.1933,  0.1199, -0.0681,  0.0192,  0.0889,  0.0570,\n",
            "        -0.3276, -0.0350, -0.0216, -0.0707], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "why\n",
            "tensor([ 8.5174e-02, -4.5700e-01,  1.1049e-01, -3.4347e-02,  7.3099e-02,\n",
            "         7.8697e-02, -1.0316e-02,  2.6729e-01, -6.5533e-02, -7.2522e-02,\n",
            "         1.0566e-01,  5.0929e-01,  2.1927e-02,  4.0559e-02, -7.6642e-02,\n",
            "        -5.3821e-01, -6.0810e-02, -2.6361e-02,  2.8657e-01, -1.0416e-02,\n",
            "         5.3501e-02,  2.1746e-01,  3.8450e-02, -1.1423e-01,  2.0169e-01,\n",
            "         6.4099e-02, -1.0864e-01, -9.8764e-02, -2.1677e-01, -7.3931e-02,\n",
            "         1.4960e-01, -3.6714e-04, -1.4275e-02, -2.4092e-01,  1.4513e-01,\n",
            "         7.8209e-02,  4.2851e-02,  4.0859e-02, -1.7864e-01, -5.4879e-02,\n",
            "         3.1509e-02,  1.4279e-01,  2.5480e-01,  7.3575e-02,  5.3994e-02,\n",
            "         6.4659e-02,  5.1165e-02,  7.9930e-02, -2.9878e-01,  1.3830e-01,\n",
            "        -1.8868e-01,  1.2634e-01, -1.0349e-02, -1.5827e-01,  3.2985e-02,\n",
            "        -1.2699e-01, -1.3972e-01, -1.6842e-01, -4.4328e-03,  1.7165e-01,\n",
            "         1.2967e-01,  5.6614e-01,  2.2158e-02, -1.5461e-02, -7.1758e-02,\n",
            "        -1.4546e-02, -1.0948e-01,  1.0376e-01, -3.4791e-01, -7.6972e-02,\n",
            "         3.1475e-01, -6.3821e-02,  2.1718e-01, -1.6956e-01,  2.5959e-01,\n",
            "        -3.4800e-01, -1.4744e-01, -2.1890e-01,  7.9892e-02,  3.0996e-01,\n",
            "         2.3480e-02, -2.7877e-03,  3.7321e-01,  3.6330e-01, -8.2742e-02,\n",
            "        -4.8321e-01, -8.1049e-02,  3.4198e-02, -2.0644e-01, -8.7694e-02,\n",
            "         1.8901e-01,  4.6461e-02, -1.4182e-01,  3.6880e-01, -2.5962e-01,\n",
            "         8.7431e-02, -4.7151e-01, -1.0307e-01, -2.2886e-02,  4.8283e-02],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Trump\n",
            "tensor([ 0.1261, -0.4248, -0.2400,  0.1229,  0.0211,  0.1836,  0.1117,  0.1976,\n",
            "        -0.0806,  0.0414,  0.2122,  0.1848, -0.2106, -0.0174, -0.1320, -0.3986,\n",
            "         0.0602,  0.0712, -0.0041, -0.0463, -0.1052, -0.0277, -0.1164,  0.0238,\n",
            "         0.1612,  0.1143, -0.4637, -0.2029, -0.1383, -0.0771, -0.4894,  0.1166,\n",
            "         0.1719, -0.2020,  0.1906,  0.0767,  0.0098,  0.0342, -0.0844, -0.0288,\n",
            "        -0.0057,  0.1184, -0.0125,  0.0223, -0.1158,  0.1038,  0.0257,  0.2952,\n",
            "        -0.0903,  0.0350, -0.5220, -0.0068,  0.1375,  0.1121,  0.2970,  0.1272,\n",
            "        -0.1043, -0.2945,  0.0059,  0.0513,  0.0212,  0.4030,  0.0215, -0.1033,\n",
            "         0.0068, -0.3665, -0.0329,  0.0531, -0.1535, -0.0439,  0.1349,  0.0188,\n",
            "         0.0284, -0.0083, -0.0468, -0.2127, -0.0481,  0.0803,  0.2285,  0.1440,\n",
            "         0.1002, -0.0262, -0.0674,  0.1188,  0.0345, -0.2238, -0.3090,  0.1570,\n",
            "        -0.3012,  0.0112,  0.4197, -0.0066, -0.0411,  0.0710, -0.1993, -0.3281,\n",
            "         0.0081,  0.0420, -0.3307,  0.2158], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "wo\n",
            "tensor([ 0.1865, -0.2477, -0.2896, -0.1136, -0.2778,  0.0060,  0.3518,  0.1137,\n",
            "        -0.0175,  0.0846,  0.0773,  0.0877,  0.0073, -0.2319, -0.2110, -0.2576,\n",
            "        -0.1339,  0.0064,  0.0750, -0.1332,  0.3329, -0.1349, -0.0987,  0.0450,\n",
            "         0.0509,  0.0190, -0.1404, -0.1048, -0.4247,  0.3193, -0.2075, -0.2066,\n",
            "         0.0006, -0.0372,  0.5069,  0.0087, -0.0397, -0.2054,  0.0228,  0.0404,\n",
            "         0.1048,  0.0196, -0.2460,  0.0690,  0.2429,  0.0271,  0.2447,  0.0959,\n",
            "         0.1752, -0.0157, -0.1545, -0.1052, -0.1353,  0.0334,  0.0682,  0.3453,\n",
            "         0.0449, -0.3685,  0.2898,  0.0871, -0.3018, -0.0997,  0.3055,  0.0955,\n",
            "        -0.0796, -0.1291, -0.1389,  0.1093, -0.3107, -0.0971,  0.0130,  0.0090,\n",
            "        -0.0771,  0.2033, -0.1382, -0.1007, -0.2021,  0.0574,  0.2615, -0.0580,\n",
            "         0.3398,  0.0074,  0.0522, -0.2173,  0.0140, -0.0225, -0.1576,  0.2563,\n",
            "         0.0455, -0.0098,  0.0400, -0.0324, -0.1381,  0.1108, -0.0044, -0.0138,\n",
            "        -0.0160,  0.1735, -0.2917,  0.0527], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "n't\n",
            "tensor([ 0.3106, -0.0041, -0.1298, -0.1245, -0.0397, -0.0131,  0.2051,  0.2494,\n",
            "         0.0773,  0.0595, -0.3961,  0.1088,  0.1708, -0.1242,  0.0251, -0.3684,\n",
            "        -0.0181,  0.1930, -0.2930, -0.1972,  0.1470, -0.0801, -0.1415,  0.2571,\n",
            "         0.4062,  0.3928, -0.0032,  0.0179, -0.1796,  0.2515, -0.4158, -0.0705,\n",
            "        -0.4330,  0.2750,  0.0280,  0.0302, -0.1088, -0.2542, -0.2954, -0.0345,\n",
            "        -0.0077, -0.2036, -0.0758,  0.3490,  0.1303, -0.0311,  0.0696, -0.0277,\n",
            "        -0.0412, -0.2180, -0.2563, -0.1611,  0.0436,  0.4097, -0.1496,  0.2694,\n",
            "         0.0394,  0.1602,  0.1426,  0.0558, -0.1209, -0.4931,  0.0776, -0.1619,\n",
            "        -0.1870, -0.1283, -0.3128,  0.1146, -0.3457, -0.0397, -0.2386,  0.1529,\n",
            "         0.1774, -0.0041, -0.0766, -0.2175, -0.6033,  0.3238, -0.0227, -0.0593,\n",
            "         0.4051,  0.2356,  0.0897,  0.2873, -0.0319, -0.1561, -0.2480,  0.2710,\n",
            "         0.0588, -0.1024, -0.0900,  0.2362,  0.0316,  0.0214, -0.2033, -0.0987,\n",
            "        -0.0345,  0.0966, -0.0826, -0.2807], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "let\n",
            "tensor([ 0.2081, -0.0437, -0.0260,  0.0585, -0.2669, -0.1237,  0.4008,  0.0365,\n",
            "         0.0008,  0.1741, -0.1538,  0.2574,  0.3439,  0.2566, -0.2328, -0.0837,\n",
            "        -0.3871, -0.1680, -0.1241, -0.0598,  0.1291,  0.0162,  0.0973, -0.1921,\n",
            "         0.0113,  0.0012,  0.0662, -0.2173,  0.0694, -0.0810, -0.1175, -0.1606,\n",
            "        -0.0375,  0.1307,  0.0100,  0.4142, -0.2168, -0.4427, -0.1711,  0.1214,\n",
            "        -0.3787,  0.0275,  0.2995,  0.1838,  0.2706, -0.1131, -0.0712, -0.1708,\n",
            "        -0.1973,  0.2963, -0.3362,  0.0234,  0.0087,  0.1868, -0.0195,  0.0026,\n",
            "         0.0684, -0.0778,  0.1580,  0.1782,  0.0960, -0.2072, -0.0805,  0.1380,\n",
            "         0.2478,  0.0341, -0.2887,  0.0325, -0.2725, -0.0258, -0.3576, -0.0550,\n",
            "         0.0741, -0.0200,  0.0670, -0.1449, -0.1501,  0.2310, -0.1741, -0.1634,\n",
            "         0.2763,  0.1704,  0.0248, -0.0261,  0.3246,  0.0050,  0.0406,  0.3440,\n",
            "         0.2831, -0.0599, -0.2163, -0.0980, -0.2348,  0.0370, -0.2189,  0.0606,\n",
            "         0.0959,  0.2158, -0.0166, -0.0910], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "women\n",
            "tensor([ 0.1181,  0.1921,  0.0213,  0.0106, -0.0395, -0.1435,  0.3091,  0.0228,\n",
            "        -0.5280, -0.0055, -0.1715,  0.2956,  0.1634,  0.1112, -0.0815, -0.1348,\n",
            "        -0.0329, -0.5196, -0.4016,  0.0562,  0.0613, -0.1051, -0.0231, -0.1727,\n",
            "        -0.2003, -0.1862, -0.1563, -0.0136,  0.0906, -0.1731, -0.1343,  0.1070,\n",
            "        -0.0427,  0.3263, -0.0483,  0.1133, -0.1895, -0.1752, -0.2412,  0.1821,\n",
            "        -0.2733,  0.1615, -0.0285,  0.0108,  0.0818, -0.2175, -0.2396, -0.1519,\n",
            "        -0.0018,  0.0317, -0.4677, -0.0337,  0.3261,  0.2690, -0.5265,  0.0433,\n",
            "         0.0473, -0.0910,  0.0114, -0.1166,  0.1132,  0.0285, -0.1339, -0.0187,\n",
            "         0.0225, -0.4374, -0.1437,  0.0443, -0.1198,  0.0416, -0.1600,  0.1102,\n",
            "         0.0855,  0.0830,  0.2605, -0.0385,  0.0281,  0.0203, -0.2252,  0.1901,\n",
            "         0.0948, -0.2709, -0.0461, -0.2783,  0.1177, -0.1687,  0.3011,  0.0661,\n",
            "         0.1994,  0.0140, -0.0479, -0.1433,  0.0168,  0.1295,  0.0279, -0.0547,\n",
            "        -0.1504,  0.3165,  0.1842, -0.0169], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "on\n",
            "tensor([ 0.2120,  0.2336,  0.0545,  0.1246, -0.1139,  0.0787,  0.3927,  0.1439,\n",
            "        -0.0564,  0.0516, -0.2727, -0.0035,  0.2991,  0.0471, -0.2965,  0.0429,\n",
            "        -0.0651, -0.0209,  0.0111,  0.1143,  0.0685, -0.0136,  0.0018, -0.2961,\n",
            "        -0.0269, -0.0269, -0.1447,  0.0427, -0.2838,  0.1639, -0.0378, -0.2481,\n",
            "        -0.0695,  0.0384, -0.3513, -0.2977,  0.0100, -0.0959, -0.0249,  0.1008,\n",
            "        -0.2359,  0.3761,  0.0721, -0.3441,  0.0201, -0.1042,  0.0195,  0.0089,\n",
            "         0.0485,  0.0789, -0.4929,  0.0920, -0.2284,  0.2581, -0.2462, -0.1775,\n",
            "         0.0842, -0.0979,  0.0486, -0.0243,  0.4859, -0.0108, -0.1493,  0.0792,\n",
            "         0.1995,  0.0264,  0.0572,  0.1461,  0.0522, -0.1102, -0.0767, -0.0533,\n",
            "         0.0185, -0.0293, -0.0094,  0.0239, -0.0345,  0.1745, -0.1272,  0.0534,\n",
            "         0.1122, -0.0316, -0.2832, -0.2390,  0.1748,  0.0283,  0.2651, -0.1213,\n",
            "         0.2542,  0.1024, -0.1053,  0.0837,  0.0507, -0.2762,  0.2285,  0.0193,\n",
            "        -0.3406,  0.2056, -0.0522,  0.1689], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "the\n",
            "tensor([ 2.5085e-01,  5.2489e-01,  5.2200e-02,  3.0469e-03, -1.8160e-01,\n",
            "         2.0509e-01,  2.2375e-01,  1.2263e-01,  3.1764e-01,  1.5724e-01,\n",
            "        -1.3482e-01, -3.5043e-02,  3.1582e-01, -8.3795e-02,  1.7914e-02,\n",
            "        -1.3698e-01, -2.8495e-02, -2.9967e-01,  3.7816e-04, -3.8257e-02,\n",
            "         9.2766e-03,  1.4616e-02, -3.3821e-02,  2.0629e-03,  2.4526e-02,\n",
            "         1.0499e-03, -9.1519e-03,  1.7807e-02,  7.7400e-02,  5.6782e-02,\n",
            "        -1.7596e-01, -3.0964e-02,  7.1767e-02,  3.4568e-03,  6.9170e-02,\n",
            "        -4.1146e-02,  1.0683e-01,  1.8510e-01, -2.2830e-01,  8.1445e-02,\n",
            "        -1.9187e-01, -2.2980e-01, -4.5285e-02, -4.5618e-02, -4.1091e-03,\n",
            "        -3.2109e-02, -2.0558e-02, -2.7268e-02, -4.1785e-01,  1.1657e-01,\n",
            "        -4.2318e-01,  5.2810e-02,  4.9722e-03, -2.9624e-02, -2.6329e-01,\n",
            "         9.9129e-02,  3.8419e-02, -1.1518e-01,  7.2224e-02,  3.7388e-01,\n",
            "         2.2919e-02,  3.2693e-01,  3.2383e-02,  6.0202e-02,  5.8950e-02,\n",
            "        -1.3928e-01, -8.3599e-02,  1.7891e-01, -5.4682e-01, -1.4582e-01,\n",
            "        -9.4929e-02,  3.2400e-02, -2.1927e-01, -1.8723e-01, -1.7478e-01,\n",
            "        -1.6888e-01,  1.4191e-01,  1.1357e-01, -2.9183e-01,  7.7393e-02,\n",
            "         2.2846e-01, -1.1255e-01, -1.9419e-01,  2.2114e-01, -1.0652e-02,\n",
            "        -4.2236e-02, -1.9904e-01, -1.3375e-01,  2.7537e-02, -4.0338e-02,\n",
            "        -1.9840e-01,  1.0506e-01,  1.9657e-01,  2.3490e-01,  1.8896e-01,\n",
            "        -9.8537e-02, -4.8323e-02, -2.1149e-01,  6.6965e-02,  8.9118e-02],\n",
            "       device='cuda:0', grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "golf\n",
            "tensor([ 0.0286,  0.4989, -0.0063,  0.1310,  0.1856,  0.0282,  0.0767,  0.0108,\n",
            "         0.0786,  0.2264,  0.3311, -0.3492, -0.1246, -0.3525,  0.0340, -0.0395,\n",
            "         0.1341, -0.3158, -0.2218,  0.0485, -0.2968, -0.0068,  0.3012,  0.1760,\n",
            "        -0.1949, -0.1721,  0.0012,  0.1840,  0.0160,  0.0959,  0.0094, -0.1778,\n",
            "         0.0170,  0.0638,  0.1424, -0.0576, -0.0581, -0.0564, -0.1799,  0.0570,\n",
            "        -0.0963,  0.2657, -0.1582,  0.3075, -0.0512, -0.0930, -0.2060,  0.0782,\n",
            "        -0.2617, -0.1593,  0.1914, -0.1342, -0.2346,  0.1006, -0.3514,  0.0568,\n",
            "         0.0863, -0.0798, -0.0465,  0.1163,  0.0839,  0.1959, -0.1030, -0.1417,\n",
            "         0.0012, -0.3081,  0.2648, -0.1331, -0.2922, -0.1635, -0.0590,  0.2226,\n",
            "         0.0185,  0.2447, -0.0244, -0.0273,  0.3122, -0.1556, -0.2513,  0.2248,\n",
            "         0.0493,  0.0387,  0.1236,  0.0546, -0.0269,  0.0161, -0.2129,  0.2257,\n",
            "         0.3953, -0.1068,  0.0657,  0.3397,  0.5109,  0.2610,  0.1413, -0.1645,\n",
            "        -0.1693, -0.1271,  0.1188, -0.3986], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "course\n",
            "tensor([-0.0479,  0.1754, -0.0520, -0.0930,  0.3209, -0.1579, -0.1404,  0.3155,\n",
            "         0.1060, -0.0252, -0.2275, -0.1887,  0.0908, -0.0698, -0.0289, -0.0842,\n",
            "         0.0018,  0.0643,  0.0404, -0.1039,  0.3116,  0.0466, -0.0409,  0.2080,\n",
            "        -0.2397, -0.1368,  0.2011,  0.0154,  0.3239,  0.0883,  0.1197, -0.0350,\n",
            "         0.2621,  0.1527, -0.0007,  0.0869, -0.0965, -0.0226,  0.3892,  0.0567,\n",
            "        -0.0278,  0.0616, -0.0778,  0.1011,  0.2191,  0.1593, -0.0999, -0.0209,\n",
            "        -0.3119, -0.3019,  0.0387,  0.0479, -0.0969, -0.2302,  0.0131, -0.0473,\n",
            "        -0.0239,  0.1037,  0.2655, -0.0469, -0.0488,  0.2229, -0.0304,  0.0854,\n",
            "         0.0119, -0.0388,  0.3101, -0.0900, -0.2200,  0.0493, -0.0290, -0.1736,\n",
            "        -0.0217,  0.0272,  0.0464,  0.2949,  0.0820, -0.1915,  0.0172, -0.0149,\n",
            "        -0.1105,  0.1216, -0.0037,  0.3691,  0.0008,  0.0480,  0.0247, -0.0291,\n",
            "         0.0491, -0.0141,  0.0219,  0.0969,  0.2039,  0.1316,  0.1925, -0.0653,\n",
            "         0.0685,  0.1260, -0.3310,  0.1445], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n",
            ".\n",
            "tensor([ 0.2624,  0.2413,  0.1222, -0.2023,  0.3820, -0.2654, -0.3093,  0.0515,\n",
            "         0.2318,  0.2017, -0.3977,  0.0333,  0.0366,  0.0510,  0.0211,  0.0498,\n",
            "         0.1896,  0.1067, -0.0487, -0.0823,  0.0519, -0.0769,  0.1996,  0.0738,\n",
            "        -0.3991, -0.2588,  0.1413,  0.3310, -0.0961,  0.1701,  0.0575, -0.0607,\n",
            "         0.1661,  0.3087,  0.1463,  0.3826, -0.0249,  0.0180, -0.0329,  0.2091,\n",
            "        -0.0695,  0.1465, -0.2035, -0.0007,  0.1902,  0.0234, -0.3433, -0.1039,\n",
            "        -0.1613, -0.3801,  0.0513,  0.1447,  0.1916, -0.0968, -0.0280, -0.1410,\n",
            "         0.0433,  0.0275, -0.0753, -0.1434, -0.1706, -0.0562, -0.0962,  0.3005,\n",
            "         0.4072,  0.0483,  0.4596,  0.0010, -0.1703,  0.1735,  0.1903, -0.1674,\n",
            "         0.0281,  0.3101,  0.1225, -0.0121,  0.0582,  0.3751,  0.1026,  0.3223,\n",
            "        -0.0353,  0.1178, -0.2459,  0.0173, -0.1205,  0.0987,  0.1531, -0.1638,\n",
            "         0.0672, -0.3504, -0.1907, -0.0371, -0.0622,  0.1508,  0.1397,  0.0649,\n",
            "         0.2593,  0.2226,  0.0701,  0.4149], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4_cCuiHsAAj",
        "outputId": "be33636a-070e-45ee-d7e5-ddfda4fdc9f3"
      },
      "source": [
        "for i in range(4):\n",
        "    print(dec[i])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.0576,  0.0086,  0.1627,  0.1050,  0.0709, -0.0079,  0.0873,\n",
            "          -0.1580, -0.0468,  0.1488, -0.0952, -0.0512,  0.2427,  0.0115,\n",
            "          -0.0869,  0.0545, -0.0095, -0.0430,  0.1399,  0.2015,  0.1519,\n",
            "           0.0887, -0.0443,  0.0204,  0.1215,  0.0808, -0.0367,  0.1204,\n",
            "          -0.1028, -0.0247,  0.0463, -0.0911, -0.0046, -0.0258, -0.1187,\n",
            "          -0.1129,  0.1020, -0.0941, -0.1348,  0.1232, -0.1346, -0.0585,\n",
            "           0.2150, -0.0254,  0.0695, -0.2412,  0.0406, -0.0386, -0.2741,\n",
            "           0.1612, -0.2460, -0.0604,  0.1664, -0.2078,  0.1106, -0.0500,\n",
            "          -0.1183, -0.1632,  0.3300,  0.0408, -0.1406,  0.2410,  0.1216,\n",
            "          -0.0505, -0.0950,  0.0771,  0.0400, -0.0595, -0.0246, -0.2470,\n",
            "          -0.1390,  0.0558,  0.0748, -0.0749,  0.0563,  0.0674,  0.1807,\n",
            "          -0.1447, -0.0081, -0.0025,  0.0721,  0.1840, -0.0920,  0.0180,\n",
            "          -0.0142,  0.1209, -0.0565, -0.1928,  0.2055,  0.0058, -0.0376,\n",
            "          -0.2789, -0.3549,  0.2111,  0.1810, -0.0164, -0.1624,  0.0366,\n",
            "          -0.1402,  0.1985]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "tensor([[[ 0.0576,  0.0086,  0.1627,  0.1050,  0.0709, -0.0079,  0.0873,\n",
            "          -0.1580, -0.0468,  0.1488, -0.0952, -0.0512,  0.2427,  0.0115,\n",
            "          -0.0869,  0.0545, -0.0095, -0.0430,  0.1399,  0.2015,  0.1519,\n",
            "           0.0887, -0.0443,  0.0204,  0.1215,  0.0808, -0.0367,  0.1204,\n",
            "          -0.1028, -0.0247,  0.0463, -0.0911, -0.0046, -0.0258, -0.1187,\n",
            "          -0.1129,  0.1020, -0.0941, -0.1348,  0.1232, -0.1346, -0.0585,\n",
            "           0.2150, -0.0254,  0.0695, -0.2412,  0.0406, -0.0386, -0.2741,\n",
            "           0.1612, -0.2460, -0.0604,  0.1664, -0.2078,  0.1106, -0.0500,\n",
            "          -0.1183, -0.1632,  0.3300,  0.0408, -0.1406,  0.2410,  0.1216,\n",
            "          -0.0505, -0.0950,  0.0771,  0.0400, -0.0595, -0.0246, -0.2470,\n",
            "          -0.1390,  0.0558,  0.0748, -0.0749,  0.0563,  0.0674,  0.1807,\n",
            "          -0.1447, -0.0081, -0.0025,  0.0721,  0.1840, -0.0920,  0.0180,\n",
            "          -0.0142,  0.1209, -0.0565, -0.1928,  0.2055,  0.0058, -0.0376,\n",
            "          -0.2789, -0.3549,  0.2111,  0.1810, -0.0164, -0.1624,  0.0366,\n",
            "          -0.1402,  0.1985]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "tensor([[[ 0.0576,  0.0086,  0.1627,  0.1050,  0.0709, -0.0079,  0.0873,\n",
            "          -0.1580, -0.0468,  0.1488, -0.0952, -0.0512,  0.2427,  0.0115,\n",
            "          -0.0869,  0.0545, -0.0095, -0.0430,  0.1399,  0.2015,  0.1519,\n",
            "           0.0887, -0.0443,  0.0204,  0.1215,  0.0808, -0.0367,  0.1204,\n",
            "          -0.1028, -0.0247,  0.0463, -0.0911, -0.0046, -0.0258, -0.1187,\n",
            "          -0.1129,  0.1020, -0.0941, -0.1348,  0.1232, -0.1346, -0.0585,\n",
            "           0.2150, -0.0254,  0.0695, -0.2412,  0.0406, -0.0386, -0.2741,\n",
            "           0.1612, -0.2460, -0.0604,  0.1664, -0.2078,  0.1106, -0.0500,\n",
            "          -0.1183, -0.1632,  0.3300,  0.0408, -0.1406,  0.2410,  0.1216,\n",
            "          -0.0505, -0.0950,  0.0771,  0.0400, -0.0595, -0.0246, -0.2470,\n",
            "          -0.1390,  0.0558,  0.0748, -0.0749,  0.0563,  0.0674,  0.1807,\n",
            "          -0.1447, -0.0081, -0.0025,  0.0721,  0.1840, -0.0920,  0.0180,\n",
            "          -0.0142,  0.1209, -0.0565, -0.1928,  0.2055,  0.0058, -0.0376,\n",
            "          -0.2789, -0.3549,  0.2111,  0.1810, -0.0164, -0.1624,  0.0366,\n",
            "          -0.1402,  0.1985]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)\n",
            "tensor([[[ 0.0576,  0.0086,  0.1627,  0.1050,  0.0709, -0.0079,  0.0873,\n",
            "          -0.1580, -0.0468,  0.1488, -0.0952, -0.0512,  0.2427,  0.0115,\n",
            "          -0.0869,  0.0545, -0.0095, -0.0430,  0.1399,  0.2015,  0.1519,\n",
            "           0.0887, -0.0443,  0.0204,  0.1215,  0.0808, -0.0367,  0.1204,\n",
            "          -0.1028, -0.0247,  0.0463, -0.0911, -0.0046, -0.0258, -0.1187,\n",
            "          -0.1129,  0.1020, -0.0941, -0.1348,  0.1232, -0.1346, -0.0585,\n",
            "           0.2150, -0.0254,  0.0695, -0.2412,  0.0406, -0.0386, -0.2741,\n",
            "           0.1612, -0.2460, -0.0604,  0.1664, -0.2078,  0.1106, -0.0500,\n",
            "          -0.1183, -0.1632,  0.3300,  0.0408, -0.1406,  0.2410,  0.1216,\n",
            "          -0.0505, -0.0950,  0.0771,  0.0400, -0.0595, -0.0246, -0.2470,\n",
            "          -0.1390,  0.0558,  0.0748, -0.0749,  0.0563,  0.0674,  0.1807,\n",
            "          -0.1447, -0.0081, -0.0025,  0.0721,  0.1840, -0.0920,  0.0180,\n",
            "          -0.0142,  0.1209, -0.0565, -0.1928,  0.2055,  0.0058, -0.0376,\n",
            "          -0.2789, -0.3549,  0.2111,  0.1810, -0.0164, -0.1624,  0.0366,\n",
            "          -0.1402,  0.1985]]], device='cuda:0', grad_fn=<CudnnRnnBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olnlXOPu_nYs"
      },
      "source": [
        "\n"
      ],
      "execution_count": 136,
      "outputs": []
    }
  ]
}